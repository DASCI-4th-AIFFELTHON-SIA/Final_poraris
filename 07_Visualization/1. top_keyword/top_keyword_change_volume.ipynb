{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d10ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 2016ë…„ ì—°ê°„ í‚¤ì›Œë“œ ë³€í™” ë¶„ì„ ì‹œì‘ ===\n",
      "\n",
      "[1ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_01_keyword_grouped.json\n",
      "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2015_12_keyword_grouped.json\n",
      "  â„¹ï¸  ì „ë…„ë„(#2015) 12ì›” ë°ì´í„°ê°€ ì—†ì–´ 1ì›”ì€ 'ì‹ ê·œ'ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n",
      "  âœ“ 1ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "[2ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_02_keyword_grouped.json\n",
      "  âœ“ 2ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "[3ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_03_keyword_grouped.json\n",
      "  âœ“ 3ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "[4ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_04_keyword_grouped.json\n",
      "  âœ“ 4ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "[5ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_05_keyword_grouped.json\n",
      "  âœ“ 5ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "[6ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_06_keyword_grouped.json\n",
      "  âœ“ 6ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "[7ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_07_keyword_grouped.json\n",
      "  âœ“ 7ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "[8ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_08_keyword_grouped.json\n",
      "  âœ“ 8ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "[9ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_09_keyword_grouped.json\n",
      "  âœ“ 9ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "[10ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_10_keyword_grouped.json\n",
      "  âœ“ 10ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "[11ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_11_keyword_grouped.json\n",
      "  âœ“ 11ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "[12ì›”] ë¶„ì„ ì¤‘... -> /home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/monthly_results_cluster/2016_12_keyword_grouped.json\n",
      "  âœ“ 12ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ 10ê°œ)\n",
      "\n",
      "ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: /home/ds4_sia_nolb/#FINAL_POLARIS/07_Visualization/1.top_keyword/monthly_keyword_change_volume/yearly_analysis_2016.json\n",
      "\n",
      "==================================================\n",
      "  2016ë…„ í‚¤ì›Œë“œ ë³€í™” ë¶„ì„ ìš”ì•½\n",
      "==================================================\n",
      "ë¶„ì„ ì™„ë£Œ ì›”ìˆ˜: 12ê°œì›”\n",
      "ì›”í‰ê·  ë¶„ì„ í‚¤ì›Œë“œ: 10.0ê°œ\n",
      "ì—°ê°„ ì‹ ê·œ í‚¤ì›Œë“œ ì´í•©: 75ê°œ\n",
      "ì›”í‰ê·  ì‹ ê·œ í‚¤ì›Œë“œ: 6.2ê°œ\n",
      "\n",
      "ì›”ë³„ í‰ê·  ë¬¸ì„œìˆ˜ ì¶”ì´:\n",
      "   1ì›”: 184.4\n",
      "   2ì›”: 355.9\n",
      "   3ì›”: 295.0\n",
      "   4ì›”: 189.9\n",
      "   5ì›”: 156.4\n",
      "   6ì›”: 113.1\n",
      "   7ì›”: 88.4\n",
      "   8ì›”: 166.5\n",
      "   9ì›”: 177.4\n",
      "  10ì›”: 111.4\n",
      "  11ì›”: 29.9\n",
      "  12ì›”: 47.8\n",
      "\n",
      "ë¶„ì„ ì™„ë£Œ ì‹œê°„: 2025-09-08T07:26:07.160485\n",
      "\n",
      "ğŸ‰ 2016ë…„ ì—°ê°„ í‚¤ì›Œë“œ ë³€í™” ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ê²°ê³¼ íŒŒì¼: /home/ds4_sia_nolb/#FINAL_POLARIS/07_Visualization/1.top_keyword/monthly_keyword_change_volume/yearly_analysis_2016.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class YearlyKeywordChangeAnalyzer:\n",
    "    \"\"\"1ë…„ê°„ í‚¤ì›Œë“œ ë³€í™”ë¥¼ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, similarity_threshold: float = 0.3):\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "    \n",
    "    def find_similar_keyword(self, current_keyword: Dict, previous_keywords: List[Dict]) -> Optional[Dict]:\n",
    "        \"\"\"í˜„ì¬ í‚¤ì›Œë“œì™€ ë¹„ìŠ·í•œ ì´ì „ í‚¤ì›Œë“œë¥¼ ì°¾ëŠ” í•¨ìˆ˜\"\"\"\n",
    "        current_phrase = current_keyword['phrase'].lower()\n",
    "        current_merged = current_keyword.get('merged_keywords', [])\n",
    "        \n",
    "        # 1. ì •í™•íˆ ê°™ì€ í‚¤ì›Œë“œ ì°¾ê¸°\n",
    "        for prev_keyword in previous_keywords:\n",
    "            if prev_keyword['phrase'].lower() == current_phrase:\n",
    "                return prev_keyword\n",
    "        \n",
    "        # 2. merged_keywordsì—ì„œ ë§¤ì¹­ ì°¾ê¸°\n",
    "        for prev_keyword in previous_keywords:\n",
    "            prev_merged = prev_keyword.get('merged_keywords', [])\n",
    "            \n",
    "            # í˜„ì¬ í‚¤ì›Œë“œì˜ merged_keywordsì™€ ì´ì „ í‚¤ì›Œë“œì˜ phrase ë¹„êµ\n",
    "            if any(merged.lower() == prev_keyword['phrase'].lower() for merged in current_merged):\n",
    "                return prev_keyword\n",
    "            \n",
    "            # í˜„ì¬ í‚¤ì›Œë“œì˜ phraseì™€ ì´ì „ í‚¤ì›Œë“œì˜ merged_keywords ë¹„êµ\n",
    "            if any(merged.lower() == current_phrase for merged in prev_merged):\n",
    "                return prev_keyword\n",
    "            \n",
    "            # merged_keywords ê°„ êµì§‘í•© í™•ì¸\n",
    "            intersection = [curr for curr in current_merged \n",
    "                          if any(prev.lower() == curr.lower() for prev in prev_merged)]\n",
    "            if intersection:\n",
    "                return prev_keyword\n",
    "        \n",
    "        # 3. ë¶€ë¶„ ë§¤ì¹­ (í‚¤ì›Œë“œ ì¼ë¶€ê°€ í¬í•¨ë˜ëŠ” ê²½ìš°)\n",
    "        for prev_keyword in previous_keywords:\n",
    "            prev_phrase = prev_keyword['phrase'].lower()\n",
    "            if current_phrase in prev_phrase or prev_phrase in current_phrase:\n",
    "                return prev_keyword\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def get_change_status(self, current: int, previous: int) -> str:\n",
    "        \"\"\"ë³€í™” ìƒíƒœë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "        if previous == 0:\n",
    "            return \"ì‹ ê·œ\"\n",
    "        change = current - previous\n",
    "        if change > 0:\n",
    "            return \"ì¦ê°€\"\n",
    "        elif change < 0:\n",
    "            return \"ê°ì†Œ\"\n",
    "        else:\n",
    "            return \"ë™ì¼\"\n",
    "    \n",
    "    def analyze_monthly_changes(self, current_data: Dict, previous_data: Optional[Dict], top_n: int = 10) -> List[Dict]:\n",
    "        \"\"\"ì›”ë³„ í‚¤ì›Œë“œ ë³€í™”ë¥¼ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "        # í˜„ì¬ ë‹¬ ìƒìœ„ Nê°œ í‚¤ì›Œë“œ\n",
    "        current_top = current_data['keywords'][:min(top_n, len(current_data['keywords']))]\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for index, current_keyword in enumerate(current_top):\n",
    "            # ì´ì „ ë‹¬ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ë¹„êµ\n",
    "            if previous_data:\n",
    "                matched_keyword = self.find_similar_keyword(current_keyword, previous_data['keywords'])\n",
    "                previous_doc_count = matched_keyword['doc_count'] if matched_keyword else 0\n",
    "                previous_score = matched_keyword['score'] if matched_keyword else 0\n",
    "                matched_phrase = matched_keyword['phrase'] if matched_keyword else \"ì—†ìŒ\"\n",
    "            else:\n",
    "                # ì²« ë²ˆì§¸ ì›”ì´ê±°ë‚˜ ì´ì „ ë°ì´í„°ê°€ ì—†ì„ ë•Œ\n",
    "                previous_doc_count = 0\n",
    "                previous_score = 0\n",
    "                matched_phrase = \"ì—†ìŒ\"\n",
    "            \n",
    "            # ë³€í™”ëŸ‰ ê³„ì‚°\n",
    "            change = current_keyword['doc_count'] - previous_doc_count\n",
    "            \n",
    "            # ë³€í™”ìœ¨ ê³„ì‚°\n",
    "            if previous_doc_count > 0:\n",
    "                change_percent = round(((current_keyword['doc_count'] - previous_doc_count) / previous_doc_count) * 100, 1)\n",
    "            else:\n",
    "                change_percent = \"ì‹ ê·œ\"\n",
    "            \n",
    "            result = {\n",
    "                'rank': index + 1,\n",
    "                'current_phrase': current_keyword['phrase'],\n",
    "                'current_doc_count': current_keyword['doc_count'],\n",
    "                'current_score': current_keyword['score'],\n",
    "                'previous_doc_count': previous_doc_count,\n",
    "                'previous_score': previous_score,\n",
    "                'change': change,\n",
    "                'change_percent': change_percent,\n",
    "                'matched_phrase': matched_phrase,\n",
    "                'status': self.get_change_status(current_keyword['doc_count'], previous_doc_count)\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def load_json_file(self, file_path: str) -> Optional[Dict]:\n",
    "        \"\"\"JSON íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                return json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
    "            return None\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"JSON íŒŒì¼ì„ ì½ëŠ”ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {file_path}\")\n",
    "            return None\n",
    "    \n",
    "    def save_results_to_json(self, results: Dict, output_path: str):\n",
    "        \"\"\"ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        try:\n",
    "            with open(output_path, 'w', encoding='utf-8') as file:\n",
    "                json.dump(results, file, ensure_ascii=False, indent=2)\n",
    "            print(f\"ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\")\n",
    "    \n",
    "    def analyze_yearly_changes(self, year: int, input_dir: str, output_path: str, top_n: int = 10):\n",
    "        \"\"\"1ë…„ê°„ì˜ í‚¤ì›Œë“œ ë³€í™”ë¥¼ ë¶„ì„í•˜ê³  ì €ì¥\"\"\"\n",
    "        yearly_results = {\n",
    "            'year': year,\n",
    "            'analysis_date': datetime.now().isoformat(),\n",
    "            'monthly_changes': {},\n",
    "            'yearly_summary': {}\n",
    "        }\n",
    "        \n",
    "        previous_month_data = None\n",
    "        all_monthly_stats = []\n",
    "        \n",
    "        print(f\"=== {year}ë…„ ì—°ê°„ í‚¤ì›Œë“œ ë³€í™” ë¶„ì„ ì‹œì‘ ===\\n\")\n",
    "        \n",
    "        # 1ì›”ë¶€í„° 12ì›”ê¹Œì§€ ìˆœì°¨ ë¶„ì„\n",
    "        for month in range(1, 13):\n",
    "            month_str = f\"{month:02d}\"\n",
    "            file_path = os.path.join(input_dir, f\"{year}_{month_str}_keyword_grouped.json\")\n",
    "            \n",
    "            print(f\"[{month}ì›”] ë¶„ì„ ì¤‘... -> {file_path}\")\n",
    "            \n",
    "            # í˜„ì¬ ì›” ë°ì´í„° ë¡œë“œ\n",
    "            current_data = self.load_json_file(file_path)\n",
    "            if current_data is None:\n",
    "                print(f\"  âš ï¸  {month}ì›” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\\n\")\n",
    "                # ì´ì „ ë‹¬ ë°ì´í„°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ (ë‹¤ìŒ ë‹¬ ë¹„êµë¥¼ ìœ„í•´)\n",
    "                continue\n",
    "\n",
    "            # âœ… ì „ì›” ë°ì´í„° ê²°ì • ë¡œì§ (ì—°ë„ ê²½ê³„ ì²˜ë¦¬ í¬í•¨)\n",
    "            if month == 1:\n",
    "                # ì „ë…„ë„ 12ì›” íŒŒì¼ ì‹œë„\n",
    "                prev_file = os.path.join(input_dir, f\"{year-1}_12_keyword_grouped.json\")\n",
    "                prev_data = self.load_json_file(prev_file)\n",
    "                if prev_data is None:\n",
    "                    print(f\"  â„¹ï¸  ì „ë…„ë„(#{year-1}) 12ì›” ë°ì´í„°ê°€ ì—†ì–´ 1ì›”ì€ 'ì‹ ê·œ'ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                # ì§ì „ ë°˜ë³µì—ì„œ ì €ì¥í•´ë‘” ë°ì´í„° ì‚¬ìš©\n",
    "                prev_data = previous_month_data\n",
    "            \n",
    "            # ì›”ë³„ ë³€í™” ë¶„ì„\n",
    "            monthly_changes = self.analyze_monthly_changes(current_data, prev_data, top_n)\n",
    "            \n",
    "            # ì›”ë³„ í†µê³„ ê³„ì‚°\n",
    "            monthly_stats = self.calculate_monthly_stats(monthly_changes, month, prev_data is not None)\n",
    "            all_monthly_stats.append(monthly_stats)\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            yearly_results['monthly_changes'][f\"{month:02d}\"] = {\n",
    "                'month': month,\n",
    "                'current_data_info': {\n",
    "                    'year': current_data.get('year', year),\n",
    "                    'month': current_data.get('month', month),\n",
    "                    'total_keywords': len(current_data['keywords'])\n",
    "                },\n",
    "                'changes': monthly_changes,\n",
    "                'stats': monthly_stats\n",
    "            }\n",
    "            \n",
    "            print(f\"  âœ“ {month}ì›” ë¶„ì„ ì™„ë£Œ (í‚¤ì›Œë“œ {len(monthly_changes)}ê°œ)\\n\")\n",
    "            \n",
    "            # ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•´ í˜„ì¬ ë°ì´í„°ë¥¼ ì´ì „ ë°ì´í„°ë¡œ ì„¤ì •\n",
    "            previous_month_data = current_data\n",
    "        \n",
    "        # ì—°ê°„ ìš”ì•½ í†µê³„ ê³„ì‚°\n",
    "        yearly_results['yearly_summary'] = self.calculate_yearly_summary(all_monthly_stats)\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        self.save_results_to_json(yearly_results, output_path)\n",
    "        \n",
    "        # ìš”ì•½ ì¶œë ¥\n",
    "        self.print_yearly_summary(yearly_results)\n",
    "        \n",
    "        return yearly_results\n",
    "    \n",
    "    def calculate_monthly_stats(self, changes: List[Dict], month: int, has_previous: bool) -> Dict:\n",
    "        \"\"\"ì›”ë³„ í†µê³„ ê³„ì‚°\"\"\"\n",
    "        if not has_previous:\n",
    "            # ì²« ë²ˆì§¸ ë‹¬ì€ (ì „ì›” ë°ì´í„° ì—†ìœ¼ë©´) ëª¨ë“  í‚¤ì›Œë“œê°€ ì‹ ê·œ\n",
    "            return {\n",
    "                'total_keywords': len(changes),\n",
    "                'new_keywords': len(changes),\n",
    "                'increased': 0,\n",
    "                'decreased': 0,\n",
    "                'unchanged': 0,\n",
    "                'biggest_increase': None,\n",
    "                'biggest_decrease': None,\n",
    "                'avg_doc_count': sum(c['current_doc_count'] for c in changes) / len(changes) if changes else 0\n",
    "            }\n",
    "        \n",
    "        new_keywords = len([c for c in changes if c['status'] == 'ì‹ ê·œ'])\n",
    "        increased = len([c for c in changes if c['status'] == 'ì¦ê°€'])\n",
    "        decreased = len([c for c in changes if c['status'] == 'ê°ì†Œ'])\n",
    "        unchanged = len([c for c in changes if c['status'] == 'ë™ì¼'])\n",
    "        \n",
    "        # ê°€ì¥ í° ë³€í™”\n",
    "        increases = [c for c in changes if c['change'] > 0]\n",
    "        decreases = [c for c in changes if c['change'] < 0]\n",
    "        \n",
    "        biggest_increase = max(increases, key=lambda x: x['change']) if increases else None\n",
    "        biggest_decrease = min(decreases, key=lambda x: x['change']) if decreases else None\n",
    "        \n",
    "        return {\n",
    "            'total_keywords': len(changes),\n",
    "            'new_keywords': new_keywords,\n",
    "            'increased': increased,\n",
    "            'decreased': decreased,\n",
    "            'unchanged': unchanged,\n",
    "            'biggest_increase': {\n",
    "                'phrase': biggest_increase['current_phrase'],\n",
    "                'change': biggest_increase['change'],\n",
    "                'change_percent': biggest_increase['change_percent']\n",
    "            } if biggest_increase else None,\n",
    "            'biggest_decrease': {\n",
    "                'phrase': biggest_decrease['current_phrase'],\n",
    "                'change': biggest_decrease['change'],\n",
    "                'change_percent': biggest_decrease['change_percent']\n",
    "            } if biggest_decrease else None,\n",
    "            'avg_doc_count': sum(c['current_doc_count'] for c in changes) / len(changes) if changes else 0\n",
    "        }\n",
    "    \n",
    "    def calculate_yearly_summary(self, monthly_stats: List[Dict]) -> Dict:\n",
    "        \"\"\"ì—°ê°„ ìš”ì•½ í†µê³„ ê³„ì‚°\"\"\"\n",
    "        if not monthly_stats:\n",
    "            return {}\n",
    "        \n",
    "        total_months = len(monthly_stats)\n",
    "        \n",
    "        return {\n",
    "            'analyzed_months': total_months,\n",
    "            'avg_keywords_per_month': sum(s['total_keywords'] for s in monthly_stats) / total_months,\n",
    "            'total_new_keywords': sum(s['new_keywords'] for s in monthly_stats),\n",
    "            'avg_new_keywords_per_month': sum(s['new_keywords'] for s in monthly_stats) / total_months,\n",
    "            'most_volatile_month': max(monthly_stats, key=lambda x: x['increased'] + x['decreased'])['total_keywords'] if monthly_stats else None,\n",
    "            'avg_doc_count_trend': [round(s['avg_doc_count'], 1) for s in monthly_stats]\n",
    "        }\n",
    "    \n",
    "    def print_yearly_summary(self, yearly_results: Dict):\n",
    "        \"\"\"ì—°ê°„ ìš”ì•½ ê²°ê³¼ ì¶œë ¥\"\"\"\n",
    "        year = yearly_results['year']\n",
    "        summary = yearly_results['yearly_summary']\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"  {year}ë…„ í‚¤ì›Œë“œ ë³€í™” ë¶„ì„ ìš”ì•½\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"ë¶„ì„ ì™„ë£Œ ì›”ìˆ˜: {summary['analyzed_months']}ê°œì›”\")\n",
    "        print(f\"ì›”í‰ê·  ë¶„ì„ í‚¤ì›Œë“œ: {summary['avg_keywords_per_month']:.1f}ê°œ\")\n",
    "        print(f\"ì—°ê°„ ì‹ ê·œ í‚¤ì›Œë“œ ì´í•©: {summary['total_new_keywords']}ê°œ\")\n",
    "        print(f\"ì›”í‰ê·  ì‹ ê·œ í‚¤ì›Œë“œ: {summary['avg_new_keywords_per_month']:.1f}ê°œ\")\n",
    "        \n",
    "        print(f\"\\nì›”ë³„ í‰ê·  ë¬¸ì„œìˆ˜ ì¶”ì´:\")\n",
    "        for i, avg_count in enumerate(summary['avg_doc_count_trend'], 1):\n",
    "            print(f\"  {i:2d}ì›”: {avg_count}\")\n",
    "        \n",
    "        print(f\"\\në¶„ì„ ì™„ë£Œ ì‹œê°„: {yearly_results['analysis_date']}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    # ë¶„ì„ê¸° ì´ˆê¸°í™”\n",
    "    analyzer = YearlyKeywordChangeAnalyzer(similarity_threshold=0.3)\n",
    "    \n",
    "    # ì„¤ì •ê°’ë“¤\n",
    "    year = 2016\n",
    "    input_directory = \"/home/ds4_sia_nolb/#FINAL_POLARIS/05_Event_top10/re_monthly_results_cluster\"\n",
    "    output_file = f\"/home/ds4_sia_nolb/#FINAL_POLARIS/07_Visualization/1.top_keyword/re_monthly_keyword_change_volume/yearly_analysis_{year}.json\"\n",
    "    top_keywords = 10\n",
    "    \n",
    "    # 1ë…„ê°„ ë¶„ì„ ì‹¤í–‰\n",
    "    results = analyzer.analyze_yearly_changes(\n",
    "        year=year,\n",
    "        input_dir=input_directory,\n",
    "        output_path=output_file,\n",
    "        top_n=top_keywords\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ‰ {year}ë…„ ì—°ê°„ í‚¤ì›Œë“œ ë³€í™” ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(f\"ê²°ê³¼ íŒŒì¼: {output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
