{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c10a34d6",
   "metadata": {},
   "source": [
    "# 최종 전처리 코드\n",
    "1. title에 [북한 날씨] 라는 단어가 들어가는 기사를 삭제하기. \n",
    "2. 똑같은 title과 본문을 가진 뉴스기사를 삭제하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3071dfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 문서 개수: 84230\n",
      "[북한날씨]/[북한 날씨] 제목 제거 수: 3443\n",
      "제거된 제목 예시(최대 10개):\n",
      " - [북한날씨] 대체로 맑음...양강도 약간의 눈\n",
      " - [북한날씨] 대체로 맑음...양강도 일부 한때 눈\n",
      " - [북한날씨] 대체로 맑음...양강도 일부 흐림\n",
      " - [북한날씨] 대체로 맑아\n",
      " - [북한날씨] 대체로 맑음...함북 일부 한때 눈\n",
      " - [북한날씨] 대체로 맑음\n",
      " - [북한날씨] 대체로 맑다가 오후부터 흐려져\n",
      " - [북한날씨] 밤에 대부분 지역 눈\n",
      " - [북한날씨] 구름 많음...동해안 대체로 맑음\n",
      " - [북한날씨] 가끔 구름...낮 최고기온 영하권\n",
      "제거 후 문서 개수: 80787\n",
      "중복 제거: 353건\n",
      "최종 문서 개수: 80434\n",
      "전처리 완료 및 저장 경로: /home/ds4_sia_nolb/#FINAL_POLARIS/04_plus_preprocessing/preprocessing_final_data/re_final_preprocessing.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# ----------------------------\n",
    "# 1. JSON 파일 불러오기\n",
    "# ----------------------------\n",
    "INPUT_PATH = \"/home/ds4_sia_nolb/#FINAL_POLARIS/04_plus_preprocessing/preprocessing_filter_data/ten_year_dprk.json\"\n",
    "OUTPUT_PATH = \"/home/ds4_sia_nolb/#FINAL_POLARIS/04_plus_preprocessing/preprocessing_final_data/re_final_preprocessing.json\"\n",
    "\n",
    "# ----------------------------\n",
    "# 2. 함수 정의\n",
    "# ----------------------------\n",
    "ZERO_WIDTH_PATTERN = re.compile(r\"[\\u200B-\\u200D\\uFEFF]\")\n",
    "\n",
    "# [북한날씨], [북한 날씨], <북한날씨>, <북한 날씨> 모두 매칭\n",
    "WEATHER_REGEX = re.compile(r\"[\\[<]북한\\s*날씨[\\]>]\")\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data if isinstance(data, list) else [data]\n",
    "\n",
    "def extract_title(doc):\n",
    "    return (doc.get(\"metadata\", {}).get(\"title\")\n",
    "            or doc.get(\"title\")\n",
    "            or \"\")\n",
    "\n",
    "def extract_text(doc):\n",
    "    txt = doc.get(\"text\")\n",
    "    if isinstance(txt, str) and txt.strip():\n",
    "        return txt\n",
    "    txt2 = doc.get(\"text_resource\", {}).get(\"text\")\n",
    "    return txt2 if isinstance(txt2, str) else \"\"\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = ZERO_WIDTH_PATTERN.sub(\"\", s)\n",
    "    return s.strip()\n",
    "\n",
    "def is_weather_tagged(title: str) -> bool:\n",
    "    t = normalize(title)\n",
    "    return bool(WEATHER_REGEX.search(t))\n",
    "\n",
    "def normalize_for_dup(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = ZERO_WIDTH_PATTERN.sub(\"\", s)\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "# ----------------------------\n",
    "# 3. 데이터 로드\n",
    "# ----------------------------\n",
    "docs = load_json(INPUT_PATH)\n",
    "print(f\"원본 문서 개수: {len(docs)}\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4. [북한 날씨] 제목 필터링\n",
    "# ----------------------------\n",
    "removed_weather = 0\n",
    "examples = []\n",
    "kept_after_weather = []\n",
    "\n",
    "for d in docs:\n",
    "    title = extract_title(d)\n",
    "    if is_weather_tagged(title):\n",
    "        removed_weather += 1\n",
    "        if len(examples) < 10:\n",
    "            examples.append(normalize(title))\n",
    "        continue\n",
    "    kept_after_weather.append(d)\n",
    "\n",
    "print(f\"[북한날씨]/[북한 날씨] 제목 제거 수: {removed_weather}\")\n",
    "if examples:\n",
    "    print(\"제거된 제목 예시(최대 10개):\")\n",
    "    for t in examples:\n",
    "        print(\" -\", t)\n",
    "print(f\"제거 후 문서 개수: {len(kept_after_weather)}\")\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5. (title + text) 중복 제거\n",
    "# ----------------------------\n",
    "seen = set()\n",
    "unique_docs = []\n",
    "dup_removed = 0\n",
    "\n",
    "for d in kept_after_weather:\n",
    "    title = extract_title(d)\n",
    "    text = extract_text(d)\n",
    "    key = (normalize_for_dup(title), normalize_for_dup(text))\n",
    "    if key in seen:\n",
    "        dup_removed += 1\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    unique_docs.append(d)\n",
    "\n",
    "print(f\"중복 제거: {dup_removed}건\")\n",
    "print(f\"최종 문서 개수: {len(unique_docs)}\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 6. 저장\n",
    "# ----------------------------\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(unique_docs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"전처리 완료 및 저장 경로: {OUTPUT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
